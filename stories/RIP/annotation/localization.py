import pickle
from collections import defaultdict
from typing import Any

import pandas as pd
import pybedtools
from biobit.core.loc import Orientation, Interval
from biobit.deprecated.gindex import GenomicIndex
from intervaltree import intervaltree
from joblib import Parallel, delayed
from tqdm import tqdm

import ld
import utils.assembly
from stories import annotation as genome_annotation
from stories.RIP import annotation, pcalling

# Load the signal cache
SIGNAL = ld.cache.signal.load()


# Load and index manual/overall annotation
def index_annotation(assembly: str) -> tuple[str, tuple[GenomicIndex, GenomicIndex]]:
    seqsizes = utils.assembly.get(name=assembly).seqid.sizes()

    # First, manual annotation
    manual = defaultdict(intervaltree.IntervalTree)
    for _, row in ld.cache.regions.load(assembly).iterrows():
        gid = row['Ensembl ID'] if not pd.isna(row['Ensembl ID']) else None
        gname = row['Gene name'] if not pd.isna(row['Gene name']) else None
        location = row['location']
        orientation = Orientation(row['strand'])

        for coords in row['intervals'].split(';'):
            start, end = coords.split('-')
            manual[row['seqid'], orientation].addi(int(start), int(end), data=(gid, gname, location))
    manual = GenomicIndex(dict(manual))

    # Next, automatic annotation based on the GENCODE annotation
    gencode = genome_annotation.load.gencode(assembly)

    exons = defaultdict(list)
    for rna in gencode.rnas.values():
        if genome_annotation.filters.is_transcription_boundary(rna):
            exons[rna.gene].extend(rna.exons)

    automatic = defaultdict(intervaltree.IntervalTree)
    boundaries = defaultdict(list)
    for gid, exons in exons.items():
        gene = gencode.genes[gid]
        gname = gene.attrs.name
        orientation = gene.loc.strand.to_orientation()

        exons = sorted(Interval.merge(exons), key=lambda x: x.start)
        start, end = exons[0].start, exons[-1].end
        boundaries[gene.loc.seqid, orientation].append((Interval(start, end), gid, gname))

        for exon in exons:
            automatic[gene.loc.seqid, orientation].addi(exon.start, exon.end, data=(gid, gname, "exonic"))
        for prv, nxt in zip(exons[:-1], exons[1:]):
            if prv.end != nxt.start:
                automatic[gene.loc.seqid, orientation].addi(prv.end, nxt.start, data=(gid, gname, "intronic"))

    # By default, we assume that intergenic regions are generated by the upstream RNA 3` elongation
    # Some records are checked manually to ensure that this is indeed the case (or to correct it)
    for (seqid, orientation), genes in boundaries.items():
        genes.sort(key=lambda x: x[0].start)

        pointer = genes[0]
        for gene in genes[1:]:
            # Embedded
            if pointer[0].start <= gene[0].start <= gene[0].end <= pointer[0].end:
                assert gene[0].start >= pointer[0].start
            # Overlapping
            elif pointer[0].start <= gene[0].start <= pointer[0].end <= gene[0].end:
                pointer = gene
            # Gapped
            else:
                assert pointer[0].start <= pointer[0].end <= gene[0].start <= gene[0].end, (pointer, gene)
                if pointer[0].end != gene[0].start:
                    match orientation:
                        case Orientation.Forward:
                            automatic[seqid, orientation].addi(
                                pointer[0].end, gene[0].start, data=(pointer[1], pointer[2], "Elongated 3` end")
                            )
                        case Orientation.Reverse:
                            automatic[seqid, orientation].addi(
                                pointer[0].end, gene[0].start, data=(gene[1], gene[2], "Elongated 3` end")
                            )
                pointer = gene

        match orientation:
            case Orientation.Forward:
                last = max(genes, key=lambda x: x[0].end)
                automatic[seqid, orientation].addi(
                    last[0].end, seqsizes[seqid], data=(last[1], last[2], "Elongated 3` end")
                )
            case Orientation.Reverse:
                first = genes[0]
                automatic[seqid, orientation].addi(
                    0, first[0].start, data=(first[1], first[2], "Elongated 3` end")
                )

    # Save as BED files for manual inspection
    bed = pybedtools.BedTool([
        pybedtools.Interval(seqid, start, end, name=f"{label} ({gname}-{gid})", strand=str(orientation))
        for (seqid, orientation), tree in automatic.items() for start, end, (gid, gname, label) in tree
    ])
    utils.bed.tbindex(bed.sort(), ld.RESULTS / f"{assembly}.auto-annotation.bed.gz")

    automatic = GenomicIndex(dict(automatic))
    return assembly, (manual, automatic)


INDICES = Parallel(n_jobs=-1, backend='sequential')(
    delayed(index_annotation)(assembly) for assembly in ["CHM13v2", "GRCm39"]
)
INDICES: dict[str, tuple[GenomicIndex, GenomicIndex]] = dict(INDICES)


def resolve_location(scores: dict[Any, float]) -> tuple[str | None, str | None, str | None]:
    if not scores:
        return None, None, None

    maxw = max(scores.items(), key=lambda x: x[1])[0]
    return maxw


def annotate(
        seqid: str, orientation: Orientation, interval: Interval, index: GenomicIndex
) -> set:
    return set(index.overlap(seqid, orientation, interval.start, interval.end).annotations)


def job(config: annotation.Config, cmp: pcalling.Config):
    host = utils.assembly.get(organism=cmp.host).name

    manual, automatic = INDICES[host]
    signal = SIGNAL[config.ind]

    results = {}
    for partition in tqdm(config.elements):
        cache = signal[partition.contig, partition.orientation]

        for (index, postfix) in (manual, "manual"), (automatic, "automatic"):
            scores = defaultdict(float)

            # Calculate scores for individual peaks
            for peak in partition.peaks:
                score = cache[cmp.project, cmp.ind][peak]
                for cat in annotate(partition.contig, partition.orientation, peak, index):
                    scores[cat] = max(scores[cat], score)

            # Calculate scores for individual invreps
            for invrep in partition.invrep:
                for arm in invrep.segments:
                    score = cache[cmp.project, cmp.ind][arm.left] + cache[cmp.project, cmp.ind][arm.right]
                    for arm in arm.left, arm.right:
                        for cat in annotate(partition.contig, partition.orientation, arm, index):
                            scores[cat] = max(scores[cat], score)

            results[partition.ind, postfix] = resolve_location(scores)
    return config.ind, cmp.ind, results


configs = annotation.Config.load()
_results = Parallel(n_jobs=-1, verbose=100, backend='multiprocessing')(
    delayed(job)(config, cmp) for config in configs for cmp in config.comparisons
)

# Group the results and save to the cache
results = defaultdict(dict)
for ind, cmp, res in _results:
    results[ind][cmp] = res

for conf in configs:
    conf.localization.parent.mkdir(parents=True, exist_ok=True)
    with open(conf.localization, 'wb') as stream:
        pickle.dump(results[conf.ind], stream)
